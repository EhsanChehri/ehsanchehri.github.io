---
layout: post
title: 15 روش شناسایی و حذف محتوای تکراری
---

یکی از عوامل مانع پیشرفت سایت ایجاد محتوای تکراری و دو به شک کردن گوگل برای رتبه بندی صفحات سایته و بهترین راه حذف محتوای تکراریه

اگر گوگل بین دو صفحه مختلف از سایت شما قادر به تفکیک نباشه اون صفحات هیچوقت به جایگاه واقعیشون در نتایج نمی‌رسن

داشتن صفحات تکراری مجازات نداره اما کاری که انجام می‌ده کم‌تر از مجازات هم نیست: افت و جلوگیری از پیشرفت کلیدواژه‌های هدف

داشتن صفحات تکراری می‌تونه دلایل بسیاری داشته باشه که باهم بررسی می‌کنیم:

## دسترسی به یک صفحه با چند آدرس مختلف

دسته‌بندی ehsaider.ir/seo اگر با آدرس ehsaider.ir/cat/seo یا ehsaider.ir/seo?utm_source همزمان در دسترس باشن خیلی ساده صفحات مشابه ساختیم

در اینجا باید یکی از حالت‌های ehsaider.ir/seo و ehsaider.ir/cat/seo به همدیگه ریدایرکت 301 بشن و برای جلوگیری از ایندکس پارامترها هم چند روش هست یکیش استفاده از کنونیکاله و یکی از طریق ابزار سرچ کنسول زیرمنوی legacy tools رو باز می‌کنیم و با انتخاب گزینه url parameters به صفحه جدیدی منتقل می‌شید که می‌تونید تعریف کنید فلان پارامتر از نتایج حذف بشه

> از کنونیکال فقط برای صفحاتی استفاده می‌شه که 100% مشابه هستن. اگر دوتا صفحه دقیقا مشابه نباشن کنونیکال نادیده گرفته می‌شه

## گرفتن لینک برای صفحات مشابه

وقتی همزمان یک صفحه با دو آدرس در دسترس باشه احتمالا خودمون یا سایر سایت‌ها به اشتباه آدرس‌های گوناگون از یک صفحه رو لینک می‌کنیم

مثلا اگر صفحه ehsaider.ir/seo با آدرس ehsaider.ir/cat/seo هم در دسترس باشه احتمال اینکه هرکدوم مجزا لینک بگیرن زیاده و اینجا گوگل نمی‌تونه تفکیک کنه کدوم صفحه اصلیه و کدوم صفحه تکراریه چون برای هردو هم کنونیکال به خود صفحه ساخته می‌شه

## کاهش بودجه خزش

ربات خزنده بودجه زیادی در اختیار سایت‌های جدید نمی‌ذاره و اگر همین بودجه هم واسه خزش صفحات مشابه هزینه بشه احتمال اینکه صفحات جدید و ارزشمند ما خیلی دیرتر ایندکس بشن زیاده

## خارج شدن صفحات از رتبه‌بندی

اگر کسی محتوای شما رو کامل منتشر کنه دچار سندیکا می‌شه و اگرم قسمتی از محتوا رو استفاده کنه مشکلی نیست اما اگر خودمون محتوای تکراری منتشر کنیم یعنی پذیرفتن اینکه صفحات از رتبه‌بندی خارج بشن و برن اون پایین پایینا

## استفاده همزمان از انواع حالت‌های دامنه سایت

احسایدر می‌تونه همزمان با www و بدون www یا http و https در دسترس باشه اما من تنها کاری که باید بکنم استفاده از یک حالت اصلی و ریدایرکت سایر حالت‌ها روی دامنه اصلیه. برای اینکار می‌تونید از htaccess استفاده کنید دستوراتش خوشبختانه زیاد پیدا می‌شه

## دسترسی به یک صفحه با حروف کوچیک و بزرگ

اگر صفحه ehsaider.ir/seo با حروف بزرگ ehsaider.ir/SEO هم در دسترس باشه بازم باهم متفاوت هستن آدرس‌ها و می‌تونن رتبه مجزا بگیرن اگه کنونیکال یا ریدایرکت نشن

## کم و زیاد کردن اسلش انتهای آدرس‌ها

به آدرس‌های زیر دقت کنید، دسترسی به یک صفحه به دو صورت با اسلش و بدون اسلش هم ممکنه پیش بیاد

```
ehsaider.ir/seo
ehsaider.ir/seo/
```

برای اینکه بدونید همچین مشکلی دارید کافیه یبار بدون اسلش و با اسلش بزنید توی نوار مرورگر. در حالت عادی باید صفحات همیشه در یک حالت در دسترس باشن و حالت دوم ریدایرکت بشه روی اصلی

## صفحات پرینت و pdf

اگر صفحات پرینت و pdf دارید باید بدونید گوگل توانایی خواندن فرمت‌های زیادی داره و براش محتوای درون صفحه و pdf یکی هستن و رتبه‌بندی می‌شن

صفحه چاپ رو کنونیکال کنید و محتوای تکراری با pdf تولید نکنید یا در صورتی که لازمه اجازه ایندکس بهش ندید با دستور htaccess می‌تونید متا نوایندکس به فایل pdf [اضافه کنید](https://webmasters.stackexchange.com/questions/14520/how-to-prevent-a-pdf-file-from-being-indexed-by-search-engines)

## آدرس مجزا برای نسخه موبایل

اگر مثل توییتر twitter.com و m.twitter.com دو آدرس مجزا برای نمایش در دسکتاپ و موبایل دارید گوگل بازم خنگ می‌شه. برای حل این مشکل از alternate و کنونیکال استفاده کنید. [google](https://developers.google.com/search/mobile-sites/mobile-seo/separate-urls#annotations-for-desktop-and-mobile-urls)

## نسخه amp صفحات

این صفحات تکراری هستن هرچند با دو آدرس مختلف

برای جلوگیری از ساخت صفحات تکراری هم باید از درون html با ویژگی amphtml لینکش کنیم و خود صفحات amp کنونیکال داشته باشن

## صفحات تگ و دسته‌بندی تکراری

اگه تازه با سئو آشنا شدید پیشنهاد می‌کنم فورا به فکر تولید محتوای انبوه نباشید تا کم کم با تکنیک‌های مختلف آشنا بشید

اگر فکر می‌کنید پستی که در مورد آهنگ مرتضی پاشایی زدید نیاز به تگ “آهنگ مرتضی پاشایی” هم داره یعنی یه جای کار ایراد داره و شما علاوه بر ساخت یک صفحه مجزا برای خواننده، در حال ساخت صفحات تکراری دیگه هم براش هستید

خیلی‌ها کلا خوبی این ویژگی تگ رو می‌ذارن کنار و اصلا ازش استفاده نمی‌کنن و خیلی‌ها میان نوایندکس می‌کنن که البته اینکار بودجه خزش هدر می‌ده پس عقلانیه استفاده نکردن ازش. اگر در دام محتوای تکراریش افتادید چاره‌ای نیست نوایندکس کنید

## صفحات پیوست تصاویر

در اکثر سیستم‌های مدیریت محتوا تصاویر هم یک صفحه مجزا دارن که چیزی جز اون تصویر نداره و البته با افزایش تصاویر تعداد این صفحات هم بیشتر می‌شه و همش مشابه. برای جلوگیری از این مشکل در وردپرس افزونه yoast نصب کنید

## صفحه‌بندی کامنت‌ها

کامنت‌ها از اون قسمتاییه که 1 ویژگی تعامل خوب با کاربرها داره و خودش به تنهایی می‌تونه مشکلات زیادی برای سایت داشته باشه مثل محتوایی تکراری، صفحه‌بندی تکراری، افزایش اسکرول صفحات، بارگیری تصاویر زیاد و لینک‌های اسپمی

اگر سایر مشکلات بخش کامنت سایتو حل کردید، برای جلوگیری از تولید صفحات تکراری افزونه yoast با نوایندکس انجامش می‌ده و یه راه حل دیگه می‌تونید این بخشو آژاکسی کنید راحت بشید یا از سیستم‌های مدیریت کامنت مثل disqus استفاده کنید

## سایت‌های چند زبانه

ساخت url مجزا برای هر زبان. گوگل ترجمه محتوا رو تا حد زیادی متوجه می‌شه و شما گزینه‌های زیادی برای تغییرات در متن ندارید مثلا تغییر واحد پولی و اینجور چیزای کوچیک

برای فرار از این ماجرا گوگل hreflang رو [پیشنهاد می‌کنه](https://support.google.com/webmasters/answer/189077)

## صفحات جستجو در سایت

این صفحات چیز جدیدی ندارن و ایندکسشون چیزی جز ضرر نداره

برای حل این مشکل می‌تونید از طریق فایل ربات دسترسیُ محدود کنید و از طریق افزونه یوآست این صفحاتو نوایندکس کنید اگر جایی لینک شدن ایندکس نشن

تا اینجا یاد گرفتیم چطوری از ایجاد صفحات تکراری جلوگیری کنیم و اگر این صفحات ساخته شدن باید چکار کنیم. از ریدایرکت برای url دوگانه، نوایندکس خارج کردن از ایندکس، دسترسی ربات برای محدود کردن مراجعه ربات خزنده و ویژگی‌های مختلف لینک‌ها مثل کنونیکال به ربات بگیم کدوم صفحه اصلیه
